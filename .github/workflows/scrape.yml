name: Daily OLX Dacha Scraper

on:
  push:            # First run when you upload/push
    branches:
      - "**"
  schedule:        # Daily at 10:00 Asia/Tashkent (UTC+5) = 05:00 UTC
    - cron: "0 5 * * *"
  workflow_dispatch: {}

permissions:
  contents: write  # to commit updated state.json

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Tashkent
      SERVICE_ACCOUNT_JSON: ${{ secrets.SERVICE_ACCOUNT_JSON }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install Python deps
        run: |
          python -m pip install -U pip
          pip install -r Project/requirements.txt

      - name: Install Playwright (browsers + libs)
        run: |
          python -m playwright install --with-deps

      - name: Restore service account file
        run: |
          cat > Project/dacha-data-scraping-bc5665b6482e.json <<'JSON'
          $SERVICE_ACCOUNT_JSON
          JSON

      - name: Run scraper
        working-directory: Project
        run: |
          python scrape_olx_dacha_tashkent.py

      - name: Upload CSV artifact
        uses: actions/upload-artifact@v4
        with:
          name: olx-dacha-csv
          path: Project/olx_dacha_tashkent_raw_*.csv
          if-no-files-found: ignore

      - name: Commit updated state.json (dedupe persistence)
        if: ${{ always() }}
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@github.com"
          git add Project/state.json
          git commit -m "Update state.json [skip ci]" || echo "No changes"
          git push
